################################################################################
# TABLEAU DE BORD AVANC√â - Monitorage externe MILDA
# Version Premium avec Architecture Modulaire et Fonctionnalit√©s Avanc√©es
################################################################################

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib
import scipy
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from datetime import datetime, timedelta
import io
import zipfile
import re
import math
import json
from pathlib import Path
from typing import Dict, List, Tuple, Optional
import warnings
warnings.filterwarnings('ignore')

# Biblioth√®ques avanc√©es
try:
    from docx import Document
    from docx.shared import Inches, Pt, RGBColor
    from docx.enum.text import WD_ALIGN_PARAGRAPH
    DOCX_AVAILABLE = True
except ImportError:
    DOCX_AVAILABLE = False

try:
    from scipy import stats
    from sklearn.preprocessing import StandardScaler
    STATS_AVAILABLE = True
except ImportError:
    STATS_AVAILABLE = False

################################################################################
# CONFIGURATION GLOBALE
################################################################################

# Configuration de la page
st.set_page_config(
    page_title="MILDA Dashboard",
    page_icon="ü¶ü",
    layout="wide",
    initial_sidebar_state="expanded",
    menu_items={
        'Get Help': 'https://www.example.com/help',
        'Report a bug': "https://www.example.com/bug",
        'About': "# MILDA Dashboard v1.0\nTableau de bord pour le monitorage de la distribution des moustiquaires au Tchad "
    }
)

# Th√®me et styles personnalis√©s
CUSTOM_CSS = """
<style>
    /* En-t√™te principal */
    .main-header {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 2rem;
        border-radius: 10px;
        color: white;
        text-align: center;
        margin-bottom: 2rem;
        box-shadow: 0 4px 6px rgba(0,0,0,0.1);
    }
    
    /* Cartes KPI */
    .kpi-card {
        background: white;
        padding: 1.5rem;
        border-radius: 10px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        border-left: 4px solid #667eea;
        margin-bottom: 1rem;
    }
    
    .kpi-value {
        font-size: 2.5rem;
        font-weight: bold;
        color: #667eea;
        margin: 0;
    }
    
    .kpi-label {
        font-size: 0.9rem;
        color: #666;
        text-transform: uppercase;
        letter-spacing: 1px;
    }
    
    .kpi-trend {
        font-size: 0.8rem;
        margin-top: 0.5rem;
    }
    
    .trend-up { color: #10b981; }
    .trend-down { color: #ef4444; }
    .trend-neutral { color: #6b7280; }
    
    /* Alertes */
    .alert-box {
        padding: 1rem;
        border-radius: 8px;
        margin: 1rem 0;
    }
    
    .alert-success { background-color: #d1fae5; border-left: 4px solid #10b981; }
    .alert-warning { background-color: #fef3c7; border-left: 4px solid #f59e0b; }
    .alert-danger { background-color: #fee2e2; border-left: 4px solid #ef4444; }
    .alert-info { background-color: #dbeafe; border-left: 4px solid #3b82f6; }
    
    /* Filtres */
    .filter-section {
        background: #f8f9fa;
        padding: 1.5rem;
        border-radius: 10px;
        margin-bottom: 1.5rem;
    }
    
    /* Tables am√©lior√©es */
    .dataframe {
        font-size: 0.9rem !important;
    }
    
    /* Badges */
    .badge {
        display: inline-block;
        padding: 0.25rem 0.75rem;
        border-radius: 12px;
        font-size: 0.8rem;
        font-weight: 600;
    }
    
    .badge-success { background-color: #d1fae5; color: #065f46; }
    .badge-warning { background-color: #fef3c7; color: #92400e; }
    .badge-danger { background-color: #fee2e2; color: #991b1b; }
    
    /* Animation de chargement */
    @keyframes pulse {
        0%, 100% { opacity: 1; }
        50% { opacity: 0.5; }
    }
    
    .loading-pulse {
        animation: pulse 2s cubic-bezier(0.4, 0, 0.6, 1) infinite;
    }
</style>
"""

st.markdown(CUSTOM_CSS, unsafe_allow_html=True)

################################################################################
# CLASSES ET STRUCTURES DE DONN√âES
################################################################################

class DataProcessor:
    """Classe pour le traitement avanc√© des donn√©es"""
    
    @staticmethod
    def normalize_yes_no(value) -> Optional[str]:
        """Normalise les r√©ponses Oui/Non avec gestion robuste"""
        if pd.isna(value):
            return None
        
        value_str = str(value).strip().lower()
        yes_values = ['oui', 'yes', 'y', '1', 'true', 'o']
        no_values = ['non', 'no', 'n', '0', 'false']
        
        if value_str in yes_values:
            return 'Oui'
        elif value_str in no_values:
            return 'Non'
        return None
    
    @staticmethod
    def calculate_expected_milda(n_persons: float) -> int:
        """Calcule le nombre de MILDA attendues (1 pour 2 personnes)"""
        try:
            if pd.isna(n_persons) or n_persons <= 0:
                return 0
            return math.ceil(float(n_persons) / 2)
        except:
            return 0
    
    @staticmethod
    def clean_column_names(df: pd.DataFrame) -> pd.DataFrame:
        """Nettoie et normalise les noms de colonnes"""
        df = df.copy()
        df.columns = df.columns.str.strip().str.lower()
        df.columns = df.columns.str.replace(r'[^\w\s]', '_', regex=True)
        df.columns = df.columns.str.replace(r'\s+', '_', regex=True)
        return df
    
    @staticmethod
    def detect_outliers(series: pd.Series, method='iqr', threshold=1.5) -> pd.Series:
        """D√©tecte les valeurs aberrantes"""
        if method == 'iqr':
            Q1 = series.quantile(0.25)
            Q3 = series.quantile(0.75)
            IQR = Q3 - Q1
            lower_bound = Q1 - threshold * IQR
            upper_bound = Q3 + threshold * IQR
            return (series < lower_bound) | (series > upper_bound)
        elif method == 'zscore' and STATS_AVAILABLE:
            z_scores = np.abs(stats.zscore(series.dropna()))
            return z_scores > threshold
        return pd.Series([False] * len(series))


class MetricsCalculator:
    """Classe pour calculer les m√©triques et indicateurs"""
    
    @staticmethod
    def calculate_coverage_metrics(df: pd.DataFrame) -> Dict:
        """Calcule les m√©triques de couverture"""
        total_households = len(df)
        served = (df['indic_servi'] == 1).sum()
        correctly_served = (df['indic_correct'] == 1).sum()
        marked = (df['indic_marque'] == 1).sum()
        informed = (df['indic_info'] == 1).sum()
        
        return {
            'total_menages': total_households,
            'menages_servis': served,
            'menages_correct': correctly_served,
            'menages_marques': marked,
            'menages_informes': informed,
            'pct_servis': round(100 * served / total_households, 2) if total_households > 0 else 0,
            'pct_correct': round(100 * correctly_served / served, 2) if served > 0 else 0,
            'pct_marques': round(100 * marked / served, 2) if served > 0 else 0,
            'pct_informes': round(100 * informed / total_households, 2) if total_households > 0 else 0
        }
    
    @staticmethod
    def calculate_distribution_accuracy(df: pd.DataFrame) -> Dict:
        """Calcule la pr√©cision de la distribution"""
        df_served = df[df['menage_servi'] == 'Oui'].copy()
        
        if len(df_served) == 0:
            return {'precision': 0, 'sur_distribution': 0, 'sous_distribution': 0}
        
        df_served['ecart'] = df_served['nb_milda_recues'] - df_served['nb_milda_attendues']
        
        correct = (df_served['ecart'] == 0).sum()
        over = (df_served['ecart'] > 0).sum()
        under = (df_served['ecart'] < 0).sum()
        
        return {
            'precision': round(100 * correct / len(df_served), 2),
            'sur_distribution': round(100 * over / len(df_served), 2),
            'sous_distribution': round(100 * under / len(df_served), 2),
            'ecart_moyen': round(df_served['ecart'].mean(), 2)
        }
    
    @staticmethod
    def calculate_quality_score(metrics: Dict) -> float:
        """Calcule un score de qualit√© global (0-100)"""
        weights = {
            'pct_servis': 0.25,
            'pct_correct': 0.30,
            'pct_marques': 0.20,
            'pct_informes': 0.25
        }
        
        score = sum(metrics.get(k, 0) * w for k, w in weights.items())
        return round(score, 2)


class VisualizationEngine:
    """Classe pour cr√©er des visualisations avanc√©es"""
    
    COLOR_PALETTE = {
        'primary': '#667eea',
        'secondary': '#764ba2',
        'success': '#10b981',
        'warning': '#f59e0b',
        'danger': '#ef4444',
        'info': '#3b82f6'
    }
    
    @classmethod
    def create_kpi_gauge(cls, value: float, title: str, max_value: float = 100,
                        threshold_good: float = 80, threshold_medium: float = 60) -> go.Figure:
        """Cr√©e un gauge KPI interactif"""
        
        # D√©terminer la couleur selon les seuils
        if value >= threshold_good:
            color = cls.COLOR_PALETTE['success']
        elif value >= threshold_medium:
            color = cls.COLOR_PALETTE['warning']
        else:
            color = cls.COLOR_PALETTE['danger']
        
        fig = go.Figure(go.Indicator(
            mode="gauge+number+delta",
            value=value,
            title={'text': title, 'font': {'size': 16}},
            delta={'reference': threshold_good, 'increasing': {'color': cls.COLOR_PALETTE['success']}},
            gauge={
                'axis': {'range': [None, max_value], 'tickwidth': 1},
                'bar': {'color': color},
                'bgcolor': "white",
                'borderwidth': 2,
                'bordercolor': "gray",
                'steps': [
                    {'range': [0, threshold_medium], 'color': '#fee2e2'},
                    {'range': [threshold_medium, threshold_good], 'color': '#fef3c7'},
                    {'range': [threshold_good, max_value], 'color': '#d1fae5'}
                ],
                'threshold': {
                    'line': {'color': "red", 'width': 4},
                    'thickness': 0.75,
                    'value': threshold_good
                }
            }
        ))
        
        fig.update_layout(
            height=250,
            margin=dict(l=20, r=20, t=50, b=20),
            paper_bgcolor="white",
            font={'color': "#333", 'family': "Arial"}
        )
        
        return fig
    
    @classmethod
    def create_stacked_bar_chart(cls, df: pd.DataFrame, x_col: str, 
                                 y_cols: List[str], title: str) -> go.Figure:
        """Cr√©e un graphique √† barres empil√©es avec annotations"""
        
        fig = go.Figure()
        
        colors = [cls.COLOR_PALETTE['primary'], cls.COLOR_PALETTE['success'], 
                 cls.COLOR_PALETTE['warning'], cls.COLOR_PALETTE['info']]
        
        for idx, col in enumerate(y_cols):
            fig.add_trace(go.Bar(
                name=col,
                x=df[x_col],
                y=df[col],
                marker_color=colors[idx % len(colors)],
                text=df[col].apply(lambda x: f'{x:.1f}%' if pd.notna(x) else ''),
                textposition='inside',
                textfont=dict(color='white', size=12),
                hovertemplate='<b>%{x}</b><br>' + col + ': %{y:.1f}%<extra></extra>'
            ))
        
        fig.update_layout(
            title={
                'text': f'<b>{title}</b>',
                'x': 0.5,
                'xanchor': 'center',
                'font': {'size': 20}
            },
            barmode='stack',
            xaxis_title="",
            yaxis_title="Pourcentage (%)",
            height=500,
            showlegend=True,
            legend=dict(
                orientation="h",
                yanchor="bottom",
                y=1.02,
                xanchor="center",
                x=0.5
            ),
            template="plotly_white",
            hovermode='x unified'
        )
        
        return fig
    
    @classmethod
    def create_comparison_chart(cls, df: pd.DataFrame, categories: str, 
                               metric: str, title: str) -> go.Figure:
        """Cr√©e un graphique de comparaison horizontal avec gradient"""
        
        df_sorted = df.sort_values(metric)
        
        # Cr√©er un gradient de couleurs
        colors = [cls.COLOR_PALETTE['danger'] if v < 60 else 
                 cls.COLOR_PALETTE['warning'] if v < 80 else 
                 cls.COLOR_PALETTE['success'] for v in df_sorted[metric]]
        
        fig = go.Figure(go.Bar(
            y=df_sorted[categories],
            x=df_sorted[metric],
            orientation='h',
            marker=dict(
                color=colors,
                line=dict(color='rgba(0,0,0,0.3)', width=1)
            ),
            text=df_sorted[metric].apply(lambda x: f'{x:.1f}%'),
            textposition='outside',
            textfont=dict(size=12),
            hovertemplate='<b>%{y}</b><br>Valeur: %{x:.1f}%<extra></extra>'
        ))
        
        fig.update_layout(
            title={'text': f'<b>{title}</b>', 'x': 0.5, 'xanchor': 'center'},
            xaxis=dict(title="Pourcentage (%)", range=[0, 105]),
            yaxis=dict(title=""),
            height=max(400, len(df) * 40),
            template="plotly_white",
            showlegend=False
        )
        
        # Ajouter une ligne de r√©f√©rence √† 80%
        fig.add_vline(x=80, line_dash="dash", line_color="red", 
                     annotation_text="Objectif 80%", annotation_position="top")
        
        return fig
    
    @classmethod
    def create_trend_chart(cls, df: pd.DataFrame, x_col: str, y_cols: List[str], 
                          title: str) -> go.Figure:
        """Cr√©e un graphique de tendance avec lignes et marqueurs"""
        
        fig = go.Figure()
        
        colors = [cls.COLOR_PALETTE['primary'], cls.COLOR_PALETTE['success'], 
                 cls.COLOR_PALETTE['warning'], cls.COLOR_PALETTE['danger']]
        
        for idx, col in enumerate(y_cols):
            fig.add_trace(go.Scatter(
                x=df[x_col],
                y=df[col],
                mode='lines+markers',
                name=col,
                line=dict(color=colors[idx % len(colors)], width=3),
                marker=dict(size=8, symbol='circle'),
                hovertemplate='<b>%{x}</b><br>' + col + ': %{y:.1f}%<extra></extra>'
            ))
        
        fig.update_layout(
            title={'text': f'<b>{title}</b>', 'x': 0.5, 'xanchor': 'center'},
            xaxis_title="",
            yaxis_title="Pourcentage (%)",
            height=450,
            template="plotly_white",
            hovermode='x unified',
            legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="center", x=0.5)
        )
        
        return fig
    
    @classmethod
    def create_heatmap(cls, df: pd.DataFrame, x_col: str, y_col: str, 
                      value_col: str, title: str) -> go.Figure:
        """Cr√©e une heatmap interactive"""
        
        pivot_df = df.pivot_table(values=value_col, index=y_col, columns=x_col, aggfunc='mean')
        
        fig = go.Figure(data=go.Heatmap(
            z=pivot_df.values,
            x=pivot_df.columns,
            y=pivot_df.index,
            colorscale='RdYlGn',
            text=np.round(pivot_df.values, 1),
            texttemplate='%{text}%',
            textfont={"size": 10},
            hovertemplate='<b>%{y}</b><br>%{x}<br>Valeur: %{z:.1f}%<extra></extra>',
            colorbar=dict(title="Pourcentage (%)")
        ))
        
        fig.update_layout(
            title={'text': f'<b>{title}</b>', 'x': 0.5, 'xanchor': 'center'},
            height=max(400, len(pivot_df) * 30),
            template="plotly_white"
        )
        
        return fig
    
    @classmethod
    def create_sunburst_chart(cls, df: pd.DataFrame, path: List[str], 
                             values: str, title: str) -> go.Figure:
        """Cr√©e un graphique sunburst hi√©rarchique"""
        
        fig = px.sunburst(
            df,
            path=path,
            values=values,
            color=values,
            color_continuous_scale='RdYlGn',
            title=f'<b>{title}</b>'
        )
        
        fig.update_layout(
            height=600,
            template="plotly_white"
        )
        
        return fig


class ReportGenerator:
    """Classe pour g√©n√©rer des rapports dans diff√©rents formats"""
    
    @staticmethod
    def generate_excel_report(data: pd.DataFrame, tables: Dict[str, pd.DataFrame], 
                             metrics: Dict) -> io.BytesIO:
        """G√©n√®re un rapport Excel multi-feuilles"""
        output = io.BytesIO()
        
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            # Feuille de r√©sum√©
            summary_df = pd.DataFrame([metrics])
            summary_df.to_excel(writer, sheet_name='R√©sum√©', index=False)
            
            # Donn√©es brutes
            data.to_excel(writer, sheet_name='Donn√©es brutes', index=False)
            
            # Tableaux d'analyse
            for name, table in tables.items():
                sheet_name = name.replace('_', ' ').title()[:31]  # Excel limite √† 31 caract√®res
                table.to_excel(writer, sheet_name=sheet_name, index=False)
        
        output.seek(0)
        return output
    
    @staticmethod
    def generate_json_report(data: pd.DataFrame, metrics: Dict) -> str:
        """G√©n√®re un rapport JSON"""
        report = {
            'metadata': {
                'generated_at': datetime.now().isoformat(),
                'total_records': len(data),
                'version': '2.0'
            },
            'metrics': metrics,
            'data_summary': {
                'provinces': data['province'].unique().tolist() if 'province' in data.columns else [],
                'districts': data['district'].unique().tolist() if 'district' in data.columns else []
            }
        }
        
        return json.dumps(report, ensure_ascii=False, indent=2)


################################################################################
# FONCTIONS DE TRAITEMENT DES DONN√âES
################################################################################

@st.cache_data(ttl=3600, show_spinner=False)
def load_and_process_data(uploaded_file, sheet_name: str = None) -> Tuple[pd.DataFrame, Dict]:
    """Charge et traite les donn√©es avec mise en cache"""
    
    try:
        # Lecture du fichier
        if sheet_name:
            try:
                data = pd.read_excel(uploaded_file, sheet_name=sheet_name)
            except:
                data = pd.read_excel(uploaded_file, sheet_name=0)
        else:
            data = pd.read_excel(uploaded_file, sheet_name=0)
        
        # Mapping des colonnes (version robuste)
        column_mapping = {
            'province': ['province', 'Province'],
            'district': ['district', 'district sanitaire', 'District sanitaire de :'],
            'centre_sante': ['centre_sante', 'centre de sant√©', 'Centre de sant√©'],
            'date_enquete': ['date_enquete', 'date_enqu√™te', 'Date enqu√™te', 'Date', 'Date de l‚Äôenqu√™te'],
            'heure_interview': ['heure_interview', 'Heure', 'time', 'heure', 'end'], 
            'agent_name': ['agent_name', "Nom de l'enqu√™teur", 'Enqu√™teur', 'Username'],
            'village': ['village', 'Village/Avenue/Quartier'],
            'menage_servi': ['menage_servi', 'Est-ce que le m√©nage a-t-il √©t√© servi en MILDA lors de la campagne de distribution de masse ?'],
            'nb_personnes': ['nb_personnes', 'Nombre des personnes qui habitent dans le m√©nage'],
            'nb_milda_recues': ['nb_milda_recues', 'Combien de MILDA avez-vous re√ßues ?'],
            'verif_cle': ['verif_cle'],
            'menage_marque': ['menage_marque', 'Est-ce que le m√©nage a  √©t√© marqu√© comme un m√©nage ayant re√ßu de MILDA?'],
            'sensibilise': ['sensibilise', 'Avez-vous √©t√© sensibilis√© sur l‚Äôutilisation correcte du MILDA par les relais communautaires ?'],
            'agent_name': ['agent_name', "Nom de l'enqu√™teur"],
            'latitude': ['latitude', '_LES COORDONNEES GEOGRAPHIQUES_latitude'],
            'longitude': ['longitude', '_LES COORDONNEES GEOGRAPHIQUES_longitude']
        }
        
        # Appliquer le mapping
        rename_dict = {}
        for target, sources in column_mapping.items():
            for source in sources:
                if source in data.columns:
                    rename_dict[source] = target
                    break
        
        data = data.rename(columns=rename_dict)
        
        # Normalisation des colonnes Oui/Non
        yes_no_cols = ['menage_servi', 'verif_cle', 'menage_marque', 'sensibilise']
        for col in yes_no_cols:
            if col in data.columns:
                data[col] = data[col].apply(DataProcessor.normalize_yes_no)
        
        # Conversion des valeurs num√©riques
        if 'nb_personnes' in data.columns:
            data['nb_personnes'] = pd.to_numeric(data['nb_personnes'], errors='coerce')
        if 'nb_milda_recues' in data.columns:
            data['nb_milda_recues'] = pd.to_numeric(data['nb_milda_recues'], errors='coerce')
        
        # Calcul des indicateurs
        if 'nb_personnes' in data.columns:
            data['nb_milda_attendues'] = data['nb_personnes'].apply(DataProcessor.calculate_expected_milda)
        
        if 'nb_milda_attendues' in data.columns and 'nb_milda_recues' in data.columns:
            data['ecart_distribution'] = data['nb_milda_recues'] - data['nb_milda_attendues']
        
        # Indicateurs binaires
        data['indic_servi'] = (data['menage_servi'] == 'Oui').astype(int)
        data['indic_correct'] = ((data['menage_servi'] == 'Oui') & (data['verif_cle'] == 'Oui')).astype(int)
        data['indic_marque'] = ((data['menage_servi'] == 'Oui') & (data['menage_marque'] == 'Oui')).astype(int)
        data['indic_info'] = (data['sensibilise'] == 'Oui').astype(int)
        
        # Conversion des dates
        if 'date_enquete' in data.columns:
            data['date_enquete'] = pd.to_datetime(data['date_enquete'], errors='coerce')
        
        # Statistiques de base
        stats = {
            'total_rows': len(data),
            'total_provinces': data['province'].nunique() if 'province' in data.columns else 0,
            'total_districts': data['district'].nunique() if 'district' in data.columns else 0,
            'date_range': (
                data['date_enquete'].min().strftime('%Y-%m-%d') if 'date_enquete' in data.columns and data['date_enquete'].notna().any() else 'N/A',
                data['date_enquete'].max().strftime('%Y-%m-%d') if 'date_enquete' in data.columns and data['date_enquete'].notna().any() else 'N/A'
            )
        }
        
        return data, stats
        
    except Exception as e:
        st.error(f"Erreur lors du chargement des donn√©es : {str(e)}")
        return pd.DataFrame(), {}


@st.cache_data(show_spinner=False)
def generate_analysis_tables(data: pd.DataFrame) -> Dict[str, pd.DataFrame]:
    """G√©n√®re les tableaux d'analyse"""
    
    tables = {}
    
    # Table 0: R√©sum√© par province
    if 'province' in data.columns:
        tables['resume_province'] = data.groupby('province').agg(
            menages_total=('province', 'count'),
            menages_servis=('indic_servi', 'sum'),
            menages_correct=('indic_correct', 'sum'),
            menages_marques=('indic_marque', 'sum'),
            menages_informes=('indic_info', 'sum'),
            pct_servis=('indic_servi', lambda x: round(100 * x.mean(), 1)),
            pct_correct=('indic_correct', lambda x: round(100 * x.mean(), 1)),
            pct_marques=('indic_marque', lambda x: round(100 * x.mean(), 1)),
            pct_informes=('indic_info', lambda x: round(100 * x.mean(), 1))
        ).reset_index()
    
    # Table 1: D√©tail par district
    if 'province' in data.columns and 'district' in data.columns:
        tables['detail_district'] = data.groupby(['province', 'district']).agg(
            menages_total=('district', 'count'),
            pct_servis=('indic_servi', lambda x: round(100 * x.mean(), 1)),
            pct_correct=('indic_correct', lambda x: round(100 * x.mean(), 1)),
            pct_marques=('indic_marque', lambda x: round(100 * x.mean(), 1)),
            pct_informes=('indic_info', lambda x: round(100 * x.mean(), 1))
        ).reset_index()
    
    # Table 2: Analyse de la distribution
    if 'ecart_distribution' in data.columns:
        distribution_df = data[data['menage_servi'] == 'Oui'].copy()
        if len(distribution_df) > 0:
            tables['analyse_distribution'] = distribution_df.groupby('province').agg(
                total=('province', 'count'),
                distribution_exacte=('ecart_distribution', lambda x: round(100 * (x == 0).mean(), 1)),
                sur_distribution=('ecart_distribution', lambda x: round(100 * (x > 0).mean(), 1)),
                sous_distribution=('ecart_distribution', lambda x: round(100 * (x < 0).mean(), 1)),
                ecart_moyen=('ecart_distribution', lambda x: round(x.mean(), 2))
            ).reset_index()
    
    # Table 3: Performance par enqu√™teur
    if 'agent_name' in data.columns:
        tables['performance_enqueteur'] = data.groupby('agent_name').agg(
            nombre_enquetes=('agent_name', 'count'),
            pct_servis=('indic_servi', lambda x: round(100 * x.mean(), 1)),
            pct_correct=('indic_correct', lambda x: round(100 * x.mean(), 1)),
            qualite_score=('indic_correct', lambda x: round(100 * x.mean(), 1))
        ).reset_index().sort_values('qualite_score', ascending=False)
    
    return tables


################################################################################
# INTERFACE UTILISATEUR - PAGES
################################################################################

def render_header():
    """Affiche l'en-t√™te principal"""
    st.markdown("""
        <div class="main-header">
            <h1>ü¶ü MILDA Dashboard</h1>
            <p style="font-size: 1.2rem; margin-top: 0.5rem;">
                Syst√®me de monitorage et d'analyse de la distribution des moustiquaires au Tchad 2026
            </p>
        </div>
    """, unsafe_allow_html=True)


def render_kpi_cards(metrics: Dict):
    """Affiche les cartes KPI principales"""
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.markdown(f"""
            <div class="kpi-card">
                <p class="kpi-label">M√©nages Servis</p>
                <p class="kpi-value">{metrics.get('pct_servis', 0):.1f}%</p>
                <p class="kpi-trend trend-{'up' if metrics.get('pct_servis', 0) >= 80 else 'down'}">
                    {'‚úì Objectif atteint' if metrics.get('pct_servis', 0) >= 80 else '‚ö† Sous objectif'}
                </p>
            </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown(f"""
            <div class="kpi-card">
                <p class="kpi-label">Distribution Correcte</p>
                <p class="kpi-value">{metrics.get('pct_correct', 0):.1f}%</p>
                <p class="kpi-trend trend-{'up' if metrics.get('pct_correct', 0) >= 80 else 'down'}">
                    {'‚úì Objectif atteint' if metrics.get('pct_correct', 0) >= 80 else '‚ö† Sous objectif'}
                </p>
            </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown(f"""
            <div class="kpi-card">
                <p class="kpi-label">M√©nages Marqu√©s</p>
                <p class="kpi-value">{metrics.get('pct_marques', 0):.1f}%</p>
                <p class="kpi-trend trend-{'up' if metrics.get('pct_marques', 0) >= 80 else 'down'}">
                    {'‚úì Objectif atteint' if metrics.get('pct_marques', 0) >= 80 else '‚ö† Sous objectif'}
                </p>
            </div>
        """, unsafe_allow_html=True)
    
    with col4:
        st.markdown(f"""
            <div class="kpi-card">
                <p class="kpi-label">M√©nages Inform√©s</p>
                <p class="kpi-value">{metrics.get('pct_informes', 0):.1f}%</p>
                <p class="kpi-trend trend-{'up' if metrics.get('pct_informes', 0) >= 80 else 'down'}">
                    {'‚úì Objectif atteint' if metrics.get('pct_informes', 0) >= 80 else '‚ö† Sous objectif'}
                </p>
            </div>
        """, unsafe_allow_html=True)


def render_alerts(metrics: Dict):
    """Affiche les alertes bas√©es sur les seuils"""
    
    alerts = []
    
    if metrics.get('pct_servis', 0) < 70:
        alerts.append(('danger', f"Taux de m√©nages servis critique: {metrics['pct_servis']:.1f}% (objectif: 80%)"))
    elif metrics.get('pct_servis', 0) < 80:
        alerts.append(('warning', f"Taux de m√©nages servis sous l'objectif: {metrics['pct_servis']:.1f}% (objectif: 80%)"))
    else:
        alerts.append(('success', f"Excellent taux de m√©nages servis: {metrics['pct_servis']:.1f}%"))
    
    if metrics.get('pct_correct', 0) < 70:
        alerts.append(('danger', f"Pr√©cision de distribution critique: {metrics['pct_correct']:.1f}%"))
    
    if metrics.get('pct_informes', 0) < 60:
        alerts.append(('warning', "Sensibilisation insuffisante sur l'utilisation des MILDA"))
    
    for alert_type, message in alerts:
        st.markdown(f"""
            <div class="alert-box alert-{alert_type}">
                <strong>{'üî¥' if alert_type == 'danger' else '‚ö†Ô∏è' if alert_type == 'warning' else '‚úÖ'}</strong> {message}
            </div>
        """, unsafe_allow_html=True)


def page_dashboard(data: pd.DataFrame, tables: Dict[str, pd.DataFrame]):
    """Page principale du dashboard"""
    
    st.markdown("## üìä Vue d'ensemble")
    
    # Calcul des m√©triques
    metrics = MetricsCalculator.calculate_coverage_metrics(data)
    quality_score = MetricsCalculator.calculate_quality_score(metrics)
    
    # KPIs principaux
    render_kpi_cards(metrics)
    
    st.markdown("---")
    
    # Alertes
    with st.expander("üîî Alertes et Notifications", expanded=True):
        render_alerts(metrics)
    
    st.markdown("---")
    
    # Graphiques principaux
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("### üìà Indicateurs par Province")
        if 'resume_province' in tables and len(tables['resume_province']) > 0:
            fig = VisualizationEngine.create_comparison_chart(
                tables['resume_province'],
                'province',
                'pct_servis',
                'Taux de couverture par province'
            )
            st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        st.markdown("### üéØ Score de qualit√© global")
        fig = VisualizationEngine.create_kpi_gauge(
            quality_score,
            "Score de qualit√©",
            max_value=100,
            threshold_good=80,
            threshold_medium=60
        )
        st.plotly_chart(fig, use_container_width=True)
    
    # Graphiques secondaires
    if 'resume_province' in tables:
        st.markdown("### üìä Comparaison des indicateurs")
        fig = VisualizationEngine.create_stacked_bar_chart(
            tables['resume_province'],
            'province',
            ['pct_servis', 'pct_correct', 'pct_marques', 'pct_informes'],
            'Indicateurs de qualit√© par province'
        )
        st.plotly_chart(fig, use_container_width=True)


def page_analysis(data: pd.DataFrame, tables: Dict[str, pd.DataFrame]):
    """Page d'analyse d√©taill√©e"""
    
    st.markdown("## üîç Analyse D√©taill√©e")
    
    # Filtres
    st.markdown('<div class="filter-section">', unsafe_allow_html=True)
    col1, col2, col3 = st.columns(3)
    
    with col1:
        provinces = ['Toutes'] + sorted(data['province'].dropna().unique().tolist())
        selected_province = st.selectbox("üó∫Ô∏è Province", provinces)
    
    with col2:
        if selected_province != 'Toutes':
            districts = ['Tous'] + sorted(data[data['province'] == selected_province]['district'].dropna().unique().tolist())
        else:
            districts = ['Tous'] + sorted(data['district'].dropna().unique().tolist())
        selected_district = st.selectbox("üìç District", districts)
    
    with col3:
        date_range = st.date_input(
            "üìÖ P√©riode",
            value=(data['date_enquete'].min(), data['date_enquete'].max()) if 'date_enquete' in data.columns else (datetime.now(), datetime.now()),
            key='date_filter'
        )
    
    st.markdown('</div>', unsafe_allow_html=True)
    
    # Filtrer les donn√©es
    filtered_data = data.copy()
    if selected_province != 'Toutes':
        filtered_data = filtered_data[filtered_data['province'] == selected_province]
    if selected_district != 'Tous':
        filtered_data = filtered_data[filtered_data['district'] == selected_district]
    
    # M√©triques filtr√©es
    st.markdown("### üìà M√©triques de la s√©lection")
    filtered_metrics = MetricsCalculator.calculate_coverage_metrics(filtered_data)
    
    col1, col2, col3, col4, col5 = st.columns(5)
    col1.metric("M√©nages analys√©s", filtered_metrics['total_menages'])
    col2.metric("Servis", f"{filtered_metrics['pct_servis']:.1f}%")
    col3.metric("Correct", f"{filtered_metrics['pct_correct']:.1f}%")
    col4.metric("Marqu√©s", f"{filtered_metrics['pct_marques']:.1f}%")
    col5.metric("Inform√©s", f"{filtered_metrics['pct_informes']:.1f}%")
    
    st.markdown("---")
    
    # Analyse de la distribution
    st.markdown("### üì¶ Analyse de la distribution")
    dist_metrics = MetricsCalculator.calculate_distribution_accuracy(filtered_data)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown(f"""
            <div class="kpi-card">
                <h4>Pr√©cision de distribution</h4>
                <p class="kpi-value">{dist_metrics['precision']:.1f}%</p>
                <p>Distribution exacte selon la norme</p>
            </div>
        """, unsafe_allow_html=True)
        
        st.markdown(f"""
            <div class="kpi-card">
                <h4>√âcart moyen</h4>
                <p class="kpi-value">{dist_metrics['ecart_moyen']:.2f}</p>
                <p>MILDA par m√©nage (√©cart √† la norme)</p>
            </div>
        """, unsafe_allow_html=True)
    
    with col2:
        # Graphique de r√©partition des √©carts
        ecart_data = pd.DataFrame({
            'Type': ['Distribution exacte', 'Sur-distribution', 'Sous-distribution'],
            'Pourcentage': [dist_metrics['precision'], dist_metrics['sur_distribution'], dist_metrics['sous_distribution']]
        })
        
        fig = px.pie(
            ecart_data,
            values='Pourcentage',
            names='Type',
            title='<b>R√©partition des types de distribution</b>',
            color_discrete_sequence=[VisualizationEngine.COLOR_PALETTE['success'], 
                                    VisualizationEngine.COLOR_PALETTE['warning'], 
                                    VisualizationEngine.COLOR_PALETTE['danger']]
        )
        fig.update_layout(height=350)
        st.plotly_chart(fig, use_container_width=True)
    
    st.markdown("---")
    
    # Tableaux d√©taill√©s
    st.markdown("### üìã Tableaux d√©taill√©s")
    
    tab1, tab2, tab3 = st.tabs(["Par District", "Par Enqu√™teur", "Distribution"])
    
    with tab1:
        if 'detail_district' in tables:
            display_table = tables['detail_district']
            if selected_province != 'Toutes':
                display_table = display_table[display_table['province'] == selected_province]
            
            st.dataframe(
                display_table.style.background_gradient(
                    subset=['pct_servis', 'pct_correct', 'pct_marques', 'pct_informes'],
                    cmap='RdYlGn',
                    vmin=0,
                    vmax=100
                ),
                use_container_width=True
            )

    
    with tab2:
        if 'performance_enqueteur' in tables:
            st.dataframe(
                tables['performance_enqueteur'].style.background_gradient(
                    subset=['qualite_score'],
                    cmap='RdYlGn',
                    vmin=0,
                    vmax=100
                ),
                use_container_width=True
            )
    
    with tab3:
        if 'analyse_distribution' in tables:
            st.dataframe(
                tables['analyse_distribution'].style.background_gradient(
                    subset=['distribution_exacte'],
                    cmap='RdYlGn',
                    vmin=0,
                    vmax=100
                ),
                use_container_width=True
            )


def page_maps(data: pd.DataFrame):
    """Page avec visualisations g√©ographiques"""
    
    st.markdown("## üó∫Ô∏è Visualisation G√©ographique")
    
    if 'latitude' not in data.columns or 'longitude' not in data.columns:
        st.warning("Donn√©es de g√©olocalisation non disponibles dans le fichier")
        return
    
    # Nettoyer les donn√©es g√©ographiques
    geo_data = data.dropna(subset=['latitude', 'longitude']).copy()
    
    if len(geo_data) == 0:
        st.warning("Aucune donn√©e g√©ographique valide trouv√©e")
        return
    
    st.info(f"üìç {len(geo_data)} m√©nages g√©olocalis√©s sur {len(data)} au total")
    
    # S√©lection du type de carte
    map_type = st.radio(
        "Type de visualisation",
        ["Carte des m√©nages", "Heatmap de densit√©", "Carte par province"],
        horizontal=True
    )
    
    if map_type == "Carte des m√©nages":
        # Carte avec marqueurs color√©s selon le statut
        geo_data['statut'] = geo_data.apply(
            lambda row: 'Servi correctement' if row['indic_correct'] == 1 
            else 'Servi' if row['indic_servi'] == 1 
            else 'Non servi',
            axis=1
        )
        
        fig = px.scatter_mapbox(
            geo_data,
            lat='latitude',
            lon='longitude',
            color='statut',
            color_discrete_map={
                'Servi correctement': VisualizationEngine.COLOR_PALETTE['success'],
                'Servi': VisualizationEngine.COLOR_PALETTE['warning'],
                'Non servi': VisualizationEngine.COLOR_PALETTE['danger']
            },
            hover_data=['province', 'district', 'village'],
            zoom=6,
            height=600,
            title='<b>Carte des m√©nages enqu√™t√©s</b>'
        )
        
        fig.update_layout(mapbox_style="open-street-map")
        st.plotly_chart(fig, use_container_width=True)
    
    elif map_type == "Heatmap de densit√©":
        fig = px.density_mapbox(
            geo_data,
            lat='latitude',
            lon='longitude',
            z='indic_servi',
            radius=10,
            zoom=6,
            height=600,
            title='<b>Densit√© des m√©nages servis</b>'
        )
        
        fig.update_layout(mapbox_style="open-street-map")
        st.plotly_chart(fig, use_container_width=True)
    
    else:  # Carte par province
        province_centers = geo_data.groupby('province').agg({
            'latitude': 'mean',
            'longitude': 'mean',
            'indic_servi': 'mean',
            'province': 'count'
        }).reset_index()
        province_centers.columns = ['province', 'latitude', 'longitude', 'taux_couverture', 'total']
        province_centers['taux_couverture'] *= 100
        
        fig = px.scatter_mapbox(
            province_centers,
            lat='latitude',
            lon='longitude',
            size='total',
            color='taux_couverture',
            color_continuous_scale='RdYlGn',
            hover_name='province',
            hover_data={'total': True, 'taux_couverture': ':.1f'},
            zoom=5,
            height=600,
            title='<b>Taux de couverture par province</b>'
        )
        
        fig.update_layout(mapbox_style="open-street-map")
        st.plotly_chart(fig, use_container_width=True)


def page_statistics(data: pd.DataFrame):
    """Page avec statistiques avanc√©es"""
    
    st.markdown("## üìä Statistiques Avanc√©es")
    
    # Statistiques descriptives
    st.markdown("### üìà Statistiques descriptives")
    
    numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()
    selected_cols = st.multiselect(
        "S√©lectionner les variables √† analyser",
        numeric_cols,
        default=['nb_personnes', 'nb_milda_recues', 'nb_milda_attendues'][:len(numeric_cols)]
    )
    
    if selected_cols:
        desc_stats = data[selected_cols].describe().T
        desc_stats['missing'] = data[selected_cols].isnull().sum()
        desc_stats['missing_pct'] = (desc_stats['missing'] / len(data) * 100).round(2)
        
        st.dataframe(desc_stats, use_container_width=True)
    
    st.markdown("---")
    
    # Distributions
    st.markdown("### üìä Distributions des variables")
    
    col1, col2 = st.columns(2)
    
    with col1:
        if 'nb_personnes' in data.columns:
            fig = px.histogram(
                data,
                x='nb_personnes',
                nbins=30,
                title='<b>Distribution de la taille des m√©nages</b>',
                color_discrete_sequence=[VisualizationEngine.COLOR_PALETTE['primary']]
            )
            fig.update_layout(height=400)
            st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        if 'ecart_distribution' in data.columns:
            fig = px.histogram(
                data[data['menage_servi'] == 'Oui'],
                x='ecart_distribution',
                nbins=20,
                title='<b>Distribution des √©carts de distribution</b>',
                color_discrete_sequence=[VisualizationEngine.COLOR_PALETTE['info']]
            )
            fig.update_layout(height=400)
            st.plotly_chart(fig, use_container_width=True)
    
    st.markdown("---")
    
    # Corr√©lations (si scipy disponible)
    if STATS_AVAILABLE and len(selected_cols) > 1:
        st.markdown("### üîó Matrice de corr√©lation")
        
        corr_matrix = data[selected_cols].corr()
        
        fig = px.imshow(
            corr_matrix,
            text_auto='.2f',
            aspect="auto",
            color_continuous_scale='RdBu_r',
            title='<b>Corr√©lations entre variables</b>'
        )
        fig.update_layout(height=500)
        st.plotly_chart(fig, use_container_width=True)
    
    # D√©tection d'anomalies
    st.markdown("### üîç D√©tection d'anomalies")
    
    if 'nb_personnes' in data.columns:
    # 1. Cr√©er une copie des donn√©es sans les valeurs manquantes pour cette colonne
    # Cela garantit que l'index de 'clean_data' sera le m√™me que celui du masque 'outliers'
        clean_data = data.dropna(subset=['nb_personnes']).copy()
    
    # 2. Calculer les outliers sur ces donn√©es propres
        outliers = DataProcessor.detect_outliers(clean_data['nb_personnes'])
        n_outliers = outliers.sum()
    
        st.info(f"üîé {n_outliers} valeurs aberrantes d√©tect√©es dans la taille des m√©nages")
    
        if n_outliers > 0:
        # 3. Utiliser clean_data (et non data) pour le filtrage
            outlier_data = clean_data[outliers]
        
            st.dataframe(
            outlier_data[['province', 'district', 'village', 'nb_personnes', 'nb_milda_recues']].head(20),
            use_container_width=True
        )


def page_export(data: pd.DataFrame, tables: Dict[str, pd.DataFrame]):
    """Page d'export et de g√©n√©ration de rapports"""
    
    st.markdown("## üì• Export et Rapports")
    
    st.markdown("### üìä Options d'export")
    
    # Calcul des m√©triques pour le rapport
    metrics = MetricsCalculator.calculate_coverage_metrics(data)
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("#### Excel")
        st.markdown("Export complet avec toutes les analyses")
        
        if st.button("üìä G√©n√©rer Excel", use_container_width=True):
            with st.spinner("G√©n√©ration du rapport Excel..."):
                excel_file = ReportGenerator.generate_excel_report(data, tables, metrics)
                st.download_button(
                    label="‚¨áÔ∏è T√©l√©charger Excel",
                    data=excel_file,
                    file_name=f"rapport_milda_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    use_container_width=True
                )
    
    with col2:
        st.markdown("#### JSON")
        st.markdown("Format structur√© pour int√©grations")
        
        if st.button("üìã G√©n√©rer JSON", use_container_width=True):
            json_report = ReportGenerator.generate_json_report(data, metrics)
            st.download_button(
                label="‚¨áÔ∏è T√©l√©charger JSON",
                data=json_report,
                file_name=f"rapport_milda_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                mime="application/json",
                use_container_width=True
            )
    
    with col3:
        st.markdown("#### CSV")
        st.markdown("Donn√©es brutes pour traitement externe")
        
        csv_data = data.to_csv(index=False).encode('utf-8')
        st.download_button(
            label="‚¨áÔ∏è T√©l√©charger CSV",
            data=csv_data,
            file_name=f"donnees_milda_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
            mime="text/csv",
            use_container_width=True
        )
    
    st.markdown("---")
    
    # Pr√©visualisation du contenu
    st.markdown("### üëÅÔ∏è Pr√©visualisation des donn√©es")
    
    preview_option = st.selectbox(
        "S√©lectionner un tableau √† pr√©visualiser",
        ["Donn√©es brutes"] + list(tables.keys())
    )
    
    if preview_option == "Donn√©es brutes":
        st.dataframe(data.head(100), use_container_width=True)
        st.caption(f"Affichage des 100 premi√®res lignes sur {len(data)} au total")
    else:
        st.dataframe(tables[preview_option], use_container_width=True)
    
    st.markdown("---")
    
    # R√©sum√© des m√©triques
    st.markdown("### üìà R√©sum√© des m√©triques")
    
    summary_df = pd.DataFrame([metrics]).T
    summary_df.columns = ['Valeur']
    st.dataframe(summary_df, use_container_width=True)

def page_agent_tracking(data: pd.DataFrame):
    st.markdown("## üèÉ Suivi du parcours des agents")
    
    df_track = data.copy()

    # 1. Conversion forc√©e de la date en format Datetime
    if 'date_enquete' in df_track.columns:
        df_track['date_enquete'] = pd.to_datetime(df_track['date_enquete'], errors='coerce')
    else:
        st.error("‚ùå Colonne 'date_enquete' manquante.")
        return

    # 2. Cr√©ation du timestamp avec gestion d'erreur robuste
    if 'heure_interview' in df_track.columns:
        # On s'assure que l'heure est au format string pour la concat√©nation
        df_track['timestamp'] = pd.to_datetime(
            df_track['date_enquete'].dt.date.astype(str) + ' ' + df_track['heure_interview'].astype(str),
            errors='coerce'
        )
    else:
        df_track['timestamp'] = df_track['date_enquete']

    # 3. Nettoyage des dates invalides (NaT) avant d'utiliser .dt
    df_track = df_track.dropna(subset=['timestamp', 'latitude', 'longitude', 'agent_name'])

    if df_track.empty:
        st.warning("‚ö†Ô∏è Aucune donn√©e chronologique ou GPS valide trouv√©e.")
        return

    # Tri chronologique
    df_track = df_track.sort_values(['agent_name', 'timestamp'])

    # S√©lecteur d'agent
    agents = sorted(df_track['agent_name'].unique())
    selected_agent = st.selectbox("S√©lectionner un enqu√™teur", agents)
    agent_path = df_track[df_track['agent_name'] == selected_agent]

    if not agent_path.empty:
        fig = px.line_mapbox(
            agent_path,
            lat="latitude",
            lon="longitude",
            hover_name=agent_path['timestamp'].dt.strftime('%H:%M'), # S√©curis√© car dropna fait avant
            zoom=10,
            height=600,
            title=f"Parcours de {selected_agent}"
        )
        
        # Ajout des points d'√©tape
        fig.add_trace(go.Scattermapbox(
            lat=agent_path['latitude'],
            lon=agent_path['longitude'],
            mode='markers+text',
            marker=go.scattermapbox.Marker(size=12, color='red'),
            # Utilisation de .dt.strftime de mani√®re s√©curis√©e
            text=agent_path['timestamp'].dt.strftime('%H:%M'),
            textposition="top right",
            name="Heure de visite"
        ))

        fig.update_layout(mapbox_style="open-street-map", showlegend=True)
        st.plotly_chart(fig, use_container_width=True)
        
def page_data_quality(data: pd.DataFrame):
    st.markdown("## üõ°Ô∏è Contr√¥le Qualit√© des Donn√©es")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("### üîç Doublons potentiels")
        # D√©tection bas√©e sur les coordonn√©es GPS et la date
        if all(c in data.columns for c in ['latitude', 'longitude', 'date_enquete']):
            duplicates = data[data.duplicated(subset=['latitude', 'longitude', 'date_enquete'], keep=False)]
            if not duplicates.empty:
                st.warning(f"‚ö†Ô∏è {len(duplicates)} lignes suspect√©es d'√™tre des doublons (GPS + Date identiques).")
                st.dataframe(duplicates)
            else:
                st.success("‚úÖ Aucun doublon GPS/Date d√©tect√©.")

    with col2:
        st.markdown("### ‚è±Ô∏è Coh√©rence temporelle")
        # V√©rifier si des interviews sont trop rapproch√©es (ex: moins de 5 min)
        if 'agent_name' in data.columns and 'timestamp' in data.columns:
            data_sorted = data.sort_values(['agent_name', 'timestamp'])
            data_sorted['diff_temps'] = data_sorted.groupby('agent_name')['timestamp'].diff().dt.total_seconds() / 60
            
            anomalies = data_sorted[data_sorted['diff_temps'] < 5] # Moins de 5 minutes
            if not anomalies.empty:
                st.error(f"üö® {len(anomalies)} interviews r√©alis√©es en moins de 5 min par le m√™me agent.")
                st.dataframe(anomalies[['agent_name', 'timestamp', 'diff_temps']])
            else:
                st.success("‚úÖ Les d√©lais entre interviews semblent r√©alistes.")

    st.markdown("---")
    st.markdown("### üìâ Analyse des valeurs manquantes")
    missing_data = data.isnull().sum()
    missing_df = pd.DataFrame({'Colonne': missing_data.index, 'Valeurs Manquantes': missing_data.values})
    fig = px.bar(missing_df, x='Colonne', y='Valeurs Manquantes', title="Champs vides par colonne")
    st.plotly_chart(fig, use_container_width=True)
    
################################################################################
# APPLICATION PRINCIPALE
################################################################################

def main():
    """Fonction principale de l'application"""
    
    # En-t√™te
    render_header()
    
    # Sidebar
    with st.sidebar:
        st.markdown("## ‚öôÔ∏è Configuration")
        
        # Upload de fichier
        uploaded_file = st.file_uploader(
            "üìÅ Importer le fichier de donn√©es",
            type=['xlsx', 'xls'],
            help="S√©lectionner un fichier Excel contenant les donn√©es d'enqu√™te"
        )
        
        if uploaded_file:
            # 1. Lire le fichier Excel pour extraire les noms de feuilles
            try:
                xls = pd.ExcelFile(uploaded_file)
                sheet_names = xls.sheet_names
                
                # 2. Cr√©er la liste d√©roulante (selectbox)
                sheet_name = st.selectbox(
                    "üìÑ Choisir la feuille de donn√©es",
                    options=sheet_names,
                    index=0,  # Par d√©faut, s√©lectionne la premi√®re feuille
                    help="S√©lectionnez la feuille qui contient les donn√©es d'enqu√™te"
                )
            except Exception as e:
                st.error(f"Erreur lors de la lecture des feuilles : {e}")
                sheet_name = None
        
        st.markdown("---")
        
        st.markdown("### üìä Indicateurs suivis")
        st.markdown("""
        - ‚úÖ % m√©nages servis
        - ‚úÖ % distribution correcte
        - ‚úÖ % m√©nages marqu√©s
        - ‚úÖ % m√©nages inform√©s
        - ‚úÖ Analyse de la distribution
        """)
        
        st.markdown("---")
        
        st.markdown("### üí° √Ä propos")
        st.markdown("""
        **Version:** 1.0
        **Date:** 2026  
        **Objectif:** 80% de couverture
        """)
        
        st.markdown("---")
        
        # Statistiques syst√®me (si donn√©es charg√©es)
        if 'data' in st.session_state and 'stats' in st.session_state:
            stats = st.session_state['stats']
            st.markdown("### üìà Statistiques")
            st.metric("Enregistrements", stats.get('total_rows', 0))
            st.metric("Provinces", stats.get('total_provinces', 0))
            st.metric("Districts", stats.get('total_districts', 0))
            
            date_range = stats.get('date_range', ('N/A', 'N/A'))
            st.caption(f"P√©riode: {date_range[0]} ‚Üí {date_range[1]}")
    
    # V√©rification du fichier
    if not uploaded_file:
        st.info("üëÜ Veuillez importer un fichier Excel pour commencer l'analyse")
        
        # Afficher un exemple de structure attendue
        st.markdown("### üìã Structure de donn√©es attendue")
        
        example_cols = [
            "province", "district", "village", "date_enquete",
            "menage_servi", "nb_personnes", "nb_milda_recues",
            "verif_cle", "menage_marque", "sensibilise"
        ]
        
        st.code("\n".join(example_cols), language="text")
        
        st.markdown("""
        **Colonnes essentielles:**
        - üó∫Ô∏è G√©ographiques: province, district, village
        - üìÖ Temporelles: date_enquete
        - üìä Distribution: menage_servi, nb_personnes, nb_milda_recues
        - ‚úÖ Qualit√©: verif_cle, menage_marque, sensibilise
        """)
        
        return
    
    # Chargement des donn√©es
    with st.spinner("üîÑ Chargement et traitement des donn√©es..."):
        data, stats = load_and_process_data(
            uploaded_file,
            sheet_name if 'sheet_name' in locals() and sheet_name else None
        )
        
        if data.empty:
            st.error("‚ùå Impossible de charger les donn√©es. V√©rifier le format du fichier.")
            return
        
        # Stocker en session
        st.session_state['data'] = data
        st.session_state['stats'] = stats
        
        # G√©n√©rer les tableaux d'analyse
        tables = generate_analysis_tables(data)
        st.session_state['tables'] = tables
    
    # Navigation par onglets
    tab1, tab2, tab3, tab4, tab5, tab6, tab7 = st.tabs([
    "üè† Dashboard", 
    "üîç Analyse", 
    "üó∫Ô∏è Cartographie", 
    "üèÉ Suivi Agents", # Nouvel onglet
    "üõ°Ô∏è Qualit√©",      # Nouvel onglet
    "üìä Statistiques",
    "üì• Export"
])
    
    with tab1:
        page_dashboard(data, tables)
    
    with tab2:
        page_analysis(data, tables)
    
    with tab3:
        page_maps(data)

    with tab4:
        page_agent_tracking(data)
        
    with tab5:
        page_data_quality(data)
        
    with tab6:
        page_statistics(data)
    
    with tab7:
        page_export(data, tables)
    
    # Footer
    st.markdown("---")
    st.markdown(f"""
        <div style='text-align: center; color: #666; padding: 20px;'>
            <p><strong>ü¶ü MILDA Dashboard v1.0</strong></p>
            <p>G√©n√©r√© le {datetime.now().strftime('%d/%m/%Y √† %H:%M:%S')}</p>
            <p style='font-size: 0.9rem;'>Syst√®me de monitorage et d'analyse de la distribution des moustiquaires</p>
        </div>
    """, unsafe_allow_html=True)


if __name__ == "__main__":
    main()
